{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a297fabe",
   "metadata": {},
   "source": [
    "First import all neccessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1c93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from preprocess import Preprocessor\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.metrics import Accuracy, Precision, Recall\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from message_encoder import *\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Nadam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee08c1",
   "metadata": {},
   "source": [
    "Next we define all hyperparameters for the Training of the LSTM module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4b3568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "# preprocessing\n",
    "log_files = [i for i in range(745, 760)]            # list of ints representing the numbers of log files to use\n",
    "logs_per_class = 100                                # How many datapoints per class should be collected if available\n",
    "window_size = 20                                    # how many log messages to be considered in a single data point from sliding window\n",
    "encoding_output_size = 16                           # size to be passed to the message_encoder, note that this is not neccessairily the shape of the output\n",
    "message_encoder = TextVectorizationEncoder(10000, True, encoding_output_size) # the message_encoder to be used. Can be TextVectorizationEncoder (uses keras.layers.TextVectorizer), BERTEncoder (only uses the BERT tokenizer) or BERTEmbeddingEncoder (also uses the BERT model)\n",
    "test_ratio = 0.2                                    # percantage of the collected data that should be used for testing rather than training\n",
    "extended_datetime_features = False                  # bool, whether the preprocessing should use a multitude of normalized features extracted from the date \n",
    "# lstm architecture\n",
    "lstm_layers = 1                                     # int, how many lstm layers to use\n",
    "lstm_units_per_layer = 50                           # int, how many lstm units per layer to use\n",
    "dropout = 0.0                                       # float, which dropout value to use, 0.0 is equivalent to not using any dropout\n",
    "recurrent_dropout = 0.0                             # float, same as with regular dropout\n",
    "# training\n",
    "epochs = 1000                                       # number of iterations to train\n",
    "batch_size = 32                                     # int, number of samples processed before updating the model weights.\n",
    "early_stopping_monitor = \"val_loss\"                 # what value to monitor for early_stopping. can be 'loss', 'val_loss', 'accuracy', 'val_accuracy', 'precision', 'val_precision', 'recall', 'val_recall', 'f1_score', 'val_f1_score'\n",
    "early_stopping_patience = 10                        # int, number of epochs to wait after no improvement, if this is greater than epochs, EarlyStopping will not apply\n",
    "early_stopping_restore_best = True                  # bool, if true keeps the best weights, not the final ones.\n",
    "validation_split = 0.1\n",
    "learning_rate = 0.001                               # float to specify learning rate of the optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate)       # optimizer, can be one of Adam, RMSprop, SGD (can have momentum parameter), Nadam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08da64",
   "metadata": {},
   "source": [
    "Next we load logs and preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47994355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.745.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca77224175724feba728d0f789010487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/811279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5b8debe9ee485cab83d22295c11d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/807974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 14\n",
      "  - 1 : 4\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.746.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58e2b6595ff4ff0a1561aebb109e670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/322863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1966f4b4954b829929f43222dc1208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/314649 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 34\n",
      "  - 1 : 10\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.747.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e236481dd2b4556a2c94cfca7f3886b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/185821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9733cbe576417988bc1bab178171d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/178255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 62\n",
      "  - 1 : 10\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.748.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bbd4a235364ed3b0f986e367170fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/217424 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c047c32d6fff45b3b1b4acfc3a900bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/207352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 100\n",
      "  - 1 : 19\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.749.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32969e89bb04f69ad0609182e1e0b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/86349 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403501e142df4c5c84455740c4e2225d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/76720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 100\n",
      "  - 1 : 37\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.750.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c645faaf3b84fa5a7a1462e0faebbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/104128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8e572993434eed90a18ea99a1bd673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/103928 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 100\n",
      "  - 1 : 55\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.751.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49422fadd6f497faba2c52f8c752607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/103334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec2dd38702a4b99878dc9f28d68d6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/103134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 100\n",
      "  - 1 : 73\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.752.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e720edb49594760b034e988eab27864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/102980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f45db7d7c4c42ed88a55b697b748f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/102703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 100\n",
      "  - 1 : 91\n",
      "Current log file: C:/Users/Askion/Documents/agmge/log-classification/data/CCI/CCLog-backup.753.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70c9650886040b0baa7426fad0f1a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file:   0%|          | 0/301697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89002e70daed4e6e87c0b0882e5b00b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/253791 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 100\n",
      "  - 1 : 100\n",
      "All states have the desired log count\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "pp = Preprocessor(log_files, \n",
    "                  message_encoder, \n",
    "                  logs_per_class=logs_per_class, \n",
    "                  window_size=window_size, \n",
    "                  extended_datetime_features=extended_datetime_features, \n",
    "                  volatile=True)\n",
    "train_data, test_data = pp.stratified_split(test_ratio=test_ratio)\n",
    "X_train, y_train = zip(*train_data)\n",
    "X_test, y_test = zip(*test_data)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf3506",
   "metadata": {},
   "source": [
    "Define the model architecture for the LSTM, then train the LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e8f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Askion\\Documents\\agmge\\log-classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.3689 - loss: 1.5960 - val_accuracy: 0.1875 - val_loss: 1.7791\n",
      "Epoch 2/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3921 - loss: 1.4858 - val_accuracy: 0.2812 - val_loss: 1.6742\n",
      "Epoch 3/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4284 - loss: 1.4116 - val_accuracy: 0.2812 - val_loss: 1.5861\n",
      "Epoch 4/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4023 - loss: 1.3562 - val_accuracy: 0.2812 - val_loss: 1.5115\n",
      "Epoch 5/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4229 - loss: 1.2772 - val_accuracy: 0.3125 - val_loss: 1.3947\n",
      "Epoch 6/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4638 - loss: 1.2230 - val_accuracy: 0.3125 - val_loss: 1.3227\n",
      "Epoch 7/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5094 - loss: 1.1610 - val_accuracy: 0.3438 - val_loss: 1.2502\n",
      "Epoch 8/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5171 - loss: 1.1154 - val_accuracy: 0.3438 - val_loss: 1.1949\n",
      "Epoch 9/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5113 - loss: 1.0628 - val_accuracy: 0.3438 - val_loss: 1.1350\n",
      "Epoch 10/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4943 - loss: 1.0420 - val_accuracy: 0.3438 - val_loss: 1.0919\n",
      "Epoch 11/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5609 - loss: 0.9607 - val_accuracy: 0.3438 - val_loss: 1.0553\n",
      "Epoch 12/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5171 - loss: 0.9833 - val_accuracy: 0.3438 - val_loss: 1.0140\n",
      "Epoch 13/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5270 - loss: 0.9413 - val_accuracy: 0.3438 - val_loss: 0.9863\n",
      "Epoch 14/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5785 - loss: 0.9079 - val_accuracy: 0.6875 - val_loss: 0.9590\n",
      "Epoch 15/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7708 - loss: 0.9029 - val_accuracy: 0.6875 - val_loss: 0.9352\n",
      "Epoch 16/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7332 - loss: 0.9017 - val_accuracy: 0.6875 - val_loss: 0.9234\n",
      "Epoch 17/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7354 - loss: 0.8814 - val_accuracy: 0.6875 - val_loss: 0.9058\n",
      "Epoch 18/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7627 - loss: 0.8676 - val_accuracy: 0.6875 - val_loss: 0.8889\n",
      "Epoch 19/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7515 - loss: 0.8533 - val_accuracy: 0.6875 - val_loss: 0.8667\n",
      "Epoch 20/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6874 - loss: 0.8620 - val_accuracy: 0.6875 - val_loss: 0.8515\n",
      "Epoch 21/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7070 - loss: 0.8266 - val_accuracy: 0.6875 - val_loss: 0.8381\n",
      "Epoch 22/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7366 - loss: 0.7830 - val_accuracy: 0.6875 - val_loss: 0.8280\n",
      "Epoch 23/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7517 - loss: 0.7884 - val_accuracy: 0.6875 - val_loss: 0.8166\n",
      "Epoch 24/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7118 - loss: 0.8101 - val_accuracy: 0.6875 - val_loss: 0.8034\n",
      "Epoch 25/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7722 - loss: 0.7732 - val_accuracy: 0.6875 - val_loss: 0.7929\n",
      "Epoch 26/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7432 - loss: 0.7881 - val_accuracy: 0.6875 - val_loss: 0.7786\n",
      "Epoch 27/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7734 - loss: 0.7498 - val_accuracy: 0.6875 - val_loss: 0.7701\n",
      "Epoch 28/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6978 - loss: 0.7794 - val_accuracy: 0.6875 - val_loss: 0.7611\n",
      "Epoch 29/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7426 - loss: 0.7709 - val_accuracy: 0.6875 - val_loss: 0.7526\n",
      "Epoch 30/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7444 - loss: 0.7240 - val_accuracy: 0.6875 - val_loss: 0.7468\n",
      "Epoch 31/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7273 - loss: 0.7263 - val_accuracy: 0.6875 - val_loss: 0.7399\n",
      "Epoch 32/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7437 - loss: 0.7249 - val_accuracy: 0.6875 - val_loss: 0.7319\n",
      "Epoch 33/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7566 - loss: 0.7331 - val_accuracy: 0.6875 - val_loss: 0.7261\n",
      "Epoch 34/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7618 - loss: 0.6990 - val_accuracy: 0.6875 - val_loss: 0.7193\n",
      "Epoch 35/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7598 - loss: 0.6857 - val_accuracy: 0.6875 - val_loss: 0.7123\n",
      "Epoch 36/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7372 - loss: 0.6961 - val_accuracy: 0.6875 - val_loss: 0.7065\n",
      "Epoch 37/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7305 - loss: 0.7005 - val_accuracy: 0.6875 - val_loss: 0.6989\n",
      "Epoch 38/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7621 - loss: 0.6957 - val_accuracy: 0.6875 - val_loss: 0.6953\n",
      "Epoch 39/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7508 - loss: 0.6877 - val_accuracy: 0.6875 - val_loss: 0.6909\n",
      "Epoch 40/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7237 - loss: 0.7048 - val_accuracy: 0.6875 - val_loss: 0.6849\n",
      "Epoch 41/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7155 - loss: 0.7004 - val_accuracy: 0.6875 - val_loss: 0.6812\n",
      "Epoch 42/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7717 - loss: 0.6542 - val_accuracy: 0.6875 - val_loss: 0.6763\n",
      "Epoch 43/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7552 - loss: 0.6628 - val_accuracy: 0.6875 - val_loss: 0.6707\n",
      "Epoch 44/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7902 - loss: 0.6664 - val_accuracy: 0.6875 - val_loss: 0.6646\n",
      "Epoch 45/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7704 - loss: 0.6600 - val_accuracy: 0.6875 - val_loss: 0.6595\n",
      "Epoch 46/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7686 - loss: 0.6796 - val_accuracy: 0.6875 - val_loss: 0.6566\n",
      "Epoch 47/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7769 - loss: 0.6782 - val_accuracy: 0.6875 - val_loss: 0.6545\n",
      "Epoch 48/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7828 - loss: 0.6374 - val_accuracy: 0.6875 - val_loss: 0.6493\n",
      "Epoch 49/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7829 - loss: 0.6203 - val_accuracy: 0.6875 - val_loss: 0.6453\n",
      "Epoch 50/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7508 - loss: 0.6442 - val_accuracy: 0.6875 - val_loss: 0.6411\n",
      "Epoch 51/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8014 - loss: 0.6332 - val_accuracy: 0.6875 - val_loss: 0.6381\n",
      "Epoch 52/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7779 - loss: 0.6598 - val_accuracy: 0.6875 - val_loss: 0.6342\n",
      "Epoch 53/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7923 - loss: 0.6473 - val_accuracy: 0.6875 - val_loss: 0.6308\n",
      "Epoch 54/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7434 - loss: 0.6351 - val_accuracy: 0.6875 - val_loss: 0.6272\n",
      "Epoch 55/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7643 - loss: 0.6319 - val_accuracy: 0.6875 - val_loss: 0.6230\n",
      "Epoch 56/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7942 - loss: 0.6128 - val_accuracy: 0.6875 - val_loss: 0.6209\n",
      "Epoch 57/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7620 - loss: 0.6203 - val_accuracy: 0.6875 - val_loss: 0.6167\n",
      "Epoch 58/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7845 - loss: 0.6075 - val_accuracy: 0.6875 - val_loss: 0.6141\n",
      "Epoch 59/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7830 - loss: 0.6248 - val_accuracy: 0.6875 - val_loss: 0.6114\n",
      "Epoch 60/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7795 - loss: 0.5982 - val_accuracy: 0.6875 - val_loss: 0.6083\n",
      "Epoch 61/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7663 - loss: 0.6205 - val_accuracy: 0.6875 - val_loss: 0.6053\n",
      "Epoch 62/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7452 - loss: 0.6479 - val_accuracy: 0.6875 - val_loss: 0.6025\n",
      "Epoch 63/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8042 - loss: 0.5972 - val_accuracy: 0.6875 - val_loss: 0.6009\n",
      "Epoch 64/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7837 - loss: 0.5851 - val_accuracy: 0.6875 - val_loss: 0.5973\n",
      "Epoch 65/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7811 - loss: 0.5855 - val_accuracy: 0.6875 - val_loss: 0.5948\n",
      "Epoch 66/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7807 - loss: 0.6200 - val_accuracy: 0.6875 - val_loss: 0.5925\n",
      "Epoch 67/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7806 - loss: 0.5842 - val_accuracy: 0.6875 - val_loss: 0.5897\n",
      "Epoch 68/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7641 - loss: 0.6040 - val_accuracy: 0.6875 - val_loss: 0.5872\n",
      "Epoch 69/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7714 - loss: 0.5939 - val_accuracy: 0.6875 - val_loss: 0.5846\n",
      "Epoch 70/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7995 - loss: 0.5786 - val_accuracy: 0.6875 - val_loss: 0.5819\n",
      "Epoch 71/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7657 - loss: 0.6105 - val_accuracy: 0.6875 - val_loss: 0.5787\n",
      "Epoch 72/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7903 - loss: 0.5936 - val_accuracy: 0.6875 - val_loss: 0.5776\n",
      "Epoch 73/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7958 - loss: 0.5860 - val_accuracy: 0.6875 - val_loss: 0.5752\n",
      "Epoch 74/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7731 - loss: 0.5794 - val_accuracy: 0.6875 - val_loss: 0.5729\n",
      "Epoch 75/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7871 - loss: 0.5699 - val_accuracy: 0.6875 - val_loss: 0.5692\n",
      "Epoch 76/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7833 - loss: 0.5757 - val_accuracy: 0.6875 - val_loss: 0.5678\n",
      "Epoch 77/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7842 - loss: 0.5734 - val_accuracy: 0.6875 - val_loss: 0.5663\n",
      "Epoch 78/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7557 - loss: 0.5943 - val_accuracy: 0.6875 - val_loss: 0.5642\n",
      "Epoch 79/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7760 - loss: 0.5864 - val_accuracy: 0.6875 - val_loss: 0.5622\n",
      "Epoch 80/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7695 - loss: 0.5785 - val_accuracy: 0.6875 - val_loss: 0.5597\n",
      "Epoch 81/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7618 - loss: 0.5550 - val_accuracy: 0.6875 - val_loss: 0.5578\n",
      "Epoch 82/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7950 - loss: 0.5776 - val_accuracy: 0.6875 - val_loss: 0.5550\n",
      "Epoch 83/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7484 - loss: 0.5980 - val_accuracy: 0.6875 - val_loss: 0.5543\n",
      "Epoch 84/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7772 - loss: 0.5515 - val_accuracy: 0.6875 - val_loss: 0.5526\n",
      "Epoch 85/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7809 - loss: 0.5583 - val_accuracy: 0.6875 - val_loss: 0.5496\n",
      "Epoch 86/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7403 - loss: 0.5917 - val_accuracy: 0.6875 - val_loss: 0.5487\n",
      "Epoch 87/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7735 - loss: 0.5445 - val_accuracy: 0.6875 - val_loss: 0.5472\n",
      "Epoch 88/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7903 - loss: 0.5264 - val_accuracy: 0.6875 - val_loss: 0.5441\n",
      "Epoch 89/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7973 - loss: 0.5702 - val_accuracy: 0.6875 - val_loss: 0.5429\n",
      "Epoch 90/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7776 - loss: 0.5719 - val_accuracy: 0.6875 - val_loss: 0.5410\n",
      "Epoch 91/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7845 - loss: 0.5220 - val_accuracy: 0.6875 - val_loss: 0.5395\n",
      "Epoch 92/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8089 - loss: 0.5217 - val_accuracy: 0.6875 - val_loss: 0.5387\n",
      "Epoch 93/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7705 - loss: 0.5319 - val_accuracy: 0.6875 - val_loss: 0.5370\n",
      "Epoch 94/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7908 - loss: 0.5513 - val_accuracy: 0.6875 - val_loss: 0.5362\n",
      "Epoch 95/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8026 - loss: 0.5040 - val_accuracy: 0.6875 - val_loss: 0.5340\n",
      "Epoch 96/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7525 - loss: 0.5497 - val_accuracy: 0.6875 - val_loss: 0.5316\n",
      "Epoch 97/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8001 - loss: 0.5255 - val_accuracy: 0.6875 - val_loss: 0.5300\n",
      "Epoch 98/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7853 - loss: 0.5531 - val_accuracy: 0.6875 - val_loss: 0.5290\n",
      "Epoch 99/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7861 - loss: 0.5247 - val_accuracy: 0.6875 - val_loss: 0.5263\n",
      "Epoch 100/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7828 - loss: 0.5477 - val_accuracy: 0.6875 - val_loss: 0.5256\n",
      "Epoch 101/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7989 - loss: 0.5154 - val_accuracy: 0.6875 - val_loss: 0.5247\n",
      "Epoch 102/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7873 - loss: 0.5194 - val_accuracy: 0.6875 - val_loss: 0.5228\n",
      "Epoch 103/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7809 - loss: 0.5559 - val_accuracy: 0.6875 - val_loss: 0.5210\n",
      "Epoch 104/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7690 - loss: 0.5259 - val_accuracy: 0.6875 - val_loss: 0.5194\n",
      "Epoch 105/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8025 - loss: 0.4927 - val_accuracy: 0.6875 - val_loss: 0.5187\n",
      "Epoch 106/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8028 - loss: 0.4989 - val_accuracy: 0.6875 - val_loss: 0.5180\n",
      "Epoch 107/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7735 - loss: 0.5080 - val_accuracy: 0.6875 - val_loss: 0.5152\n",
      "Epoch 108/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7736 - loss: 0.5023 - val_accuracy: 0.6875 - val_loss: 0.5144\n",
      "Epoch 109/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7556 - loss: 0.5385 - val_accuracy: 0.6875 - val_loss: 0.5126\n",
      "Epoch 110/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8157 - loss: 0.4821 - val_accuracy: 0.6875 - val_loss: 0.5129\n",
      "Epoch 111/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8024 - loss: 0.5059 - val_accuracy: 0.6875 - val_loss: 0.5107\n",
      "Epoch 112/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7602 - loss: 0.5474 - val_accuracy: 0.6875 - val_loss: 0.5099\n",
      "Epoch 113/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7865 - loss: 0.4974 - val_accuracy: 0.6875 - val_loss: 0.5080\n",
      "Epoch 114/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7623 - loss: 0.5207 - val_accuracy: 0.6875 - val_loss: 0.5069\n",
      "Epoch 115/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8136 - loss: 0.4769 - val_accuracy: 0.6875 - val_loss: 0.5051\n",
      "Epoch 116/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7643 - loss: 0.5257 - val_accuracy: 0.6875 - val_loss: 0.5045\n",
      "Epoch 117/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7827 - loss: 0.5485 - val_accuracy: 0.6875 - val_loss: 0.5032\n",
      "Epoch 118/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7677 - loss: 0.5239 - val_accuracy: 0.6875 - val_loss: 0.5027\n",
      "Epoch 119/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8042 - loss: 0.4991 - val_accuracy: 0.6875 - val_loss: 0.5018\n",
      "Epoch 120/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7787 - loss: 0.5210 - val_accuracy: 0.6875 - val_loss: 0.4997\n",
      "Epoch 121/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7950 - loss: 0.5012 - val_accuracy: 0.6875 - val_loss: 0.4990\n",
      "Epoch 122/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8100 - loss: 0.5096 - val_accuracy: 0.6875 - val_loss: 0.4978\n",
      "Epoch 123/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7724 - loss: 0.5183 - val_accuracy: 0.6875 - val_loss: 0.4979\n",
      "Epoch 124/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7977 - loss: 0.5152 - val_accuracy: 0.6875 - val_loss: 0.4965\n",
      "Epoch 125/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7647 - loss: 0.5043 - val_accuracy: 0.6875 - val_loss: 0.4945\n",
      "Epoch 126/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7748 - loss: 0.4616 - val_accuracy: 0.6875 - val_loss: 0.4923\n",
      "Epoch 127/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7927 - loss: 0.4728 - val_accuracy: 0.6875 - val_loss: 0.4913\n",
      "Epoch 128/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7807 - loss: 0.4854 - val_accuracy: 0.6875 - val_loss: 0.4916\n",
      "Epoch 129/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7912 - loss: 0.5362 - val_accuracy: 0.6875 - val_loss: 0.4907\n",
      "Epoch 130/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7435 - loss: 0.5388 - val_accuracy: 0.6875 - val_loss: 0.4889\n",
      "Epoch 131/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8195 - loss: 0.4471 - val_accuracy: 0.6875 - val_loss: 0.4892\n",
      "Epoch 132/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7689 - loss: 0.4840 - val_accuracy: 0.6875 - val_loss: 0.4875\n",
      "Epoch 133/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7929 - loss: 0.4783 - val_accuracy: 0.6875 - val_loss: 0.4853\n",
      "Epoch 134/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8051 - loss: 0.4401 - val_accuracy: 0.6875 - val_loss: 0.4848\n",
      "Epoch 135/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7905 - loss: 0.5030 - val_accuracy: 0.6875 - val_loss: 0.4845\n",
      "Epoch 136/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7686 - loss: 0.4870 - val_accuracy: 0.6875 - val_loss: 0.4831\n",
      "Epoch 137/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7616 - loss: 0.5097 - val_accuracy: 0.6875 - val_loss: 0.4825\n",
      "Epoch 138/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7587 - loss: 0.4860 - val_accuracy: 0.6875 - val_loss: 0.4819\n",
      "Epoch 139/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7622 - loss: 0.4808 - val_accuracy: 0.6875 - val_loss: 0.4818\n",
      "Epoch 140/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8041 - loss: 0.4640 - val_accuracy: 0.6875 - val_loss: 0.4797\n",
      "Epoch 141/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7778 - loss: 0.4929 - val_accuracy: 0.6875 - val_loss: 0.4791\n",
      "Epoch 142/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8043 - loss: 0.4882 - val_accuracy: 0.6875 - val_loss: 0.4790\n",
      "Epoch 143/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7905 - loss: 0.4771 - val_accuracy: 0.6875 - val_loss: 0.4771\n",
      "Epoch 144/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7809 - loss: 0.4757 - val_accuracy: 0.6875 - val_loss: 0.4764\n",
      "Epoch 145/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7845 - loss: 0.5051 - val_accuracy: 0.6875 - val_loss: 0.4751\n",
      "Epoch 146/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7925 - loss: 0.4792 - val_accuracy: 0.6875 - val_loss: 0.4749\n",
      "Epoch 147/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8083 - loss: 0.4542 - val_accuracy: 0.6875 - val_loss: 0.4745\n",
      "Epoch 148/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7621 - loss: 0.4839 - val_accuracy: 0.6875 - val_loss: 0.4723\n",
      "Epoch 149/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8085 - loss: 0.4421 - val_accuracy: 0.6875 - val_loss: 0.4716\n",
      "Epoch 150/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7910 - loss: 0.4756 - val_accuracy: 0.6875 - val_loss: 0.4717\n",
      "Epoch 151/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7929 - loss: 0.4673 - val_accuracy: 0.6875 - val_loss: 0.4711\n",
      "Epoch 152/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7865 - loss: 0.4709 - val_accuracy: 0.6875 - val_loss: 0.4694\n",
      "Epoch 153/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7750 - loss: 0.4831 - val_accuracy: 0.6875 - val_loss: 0.4686\n",
      "Epoch 154/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8018 - loss: 0.4918 - val_accuracy: 0.6875 - val_loss: 0.4678\n",
      "Epoch 155/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8193 - loss: 0.4454 - val_accuracy: 0.6875 - val_loss: 0.4690\n",
      "Epoch 156/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7696 - loss: 0.5103 - val_accuracy: 0.6875 - val_loss: 0.4676\n",
      "Epoch 157/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8244 - loss: 0.4483 - val_accuracy: 0.6875 - val_loss: 0.4670\n",
      "Epoch 158/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7732 - loss: 0.4414 - val_accuracy: 0.6875 - val_loss: 0.4648\n",
      "Epoch 159/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7931 - loss: 0.4576 - val_accuracy: 0.6875 - val_loss: 0.4631\n",
      "Epoch 160/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8177 - loss: 0.4329 - val_accuracy: 0.6875 - val_loss: 0.4629\n",
      "Epoch 161/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7502 - loss: 0.4998 - val_accuracy: 0.6875 - val_loss: 0.4614\n",
      "Epoch 162/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7912 - loss: 0.4931 - val_accuracy: 0.6875 - val_loss: 0.4621\n",
      "Epoch 163/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7949 - loss: 0.4720 - val_accuracy: 0.6875 - val_loss: 0.4612\n",
      "Epoch 164/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7914 - loss: 0.4648 - val_accuracy: 0.6875 - val_loss: 0.4606\n",
      "Epoch 165/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8039 - loss: 0.4368 - val_accuracy: 0.6875 - val_loss: 0.4600\n",
      "Epoch 166/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7983 - loss: 0.4573 - val_accuracy: 0.6875 - val_loss: 0.4589\n",
      "Epoch 167/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8061 - loss: 0.4475 - val_accuracy: 0.6875 - val_loss: 0.4600\n",
      "Epoch 168/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8242 - loss: 0.4472 - val_accuracy: 0.6875 - val_loss: 0.4595\n",
      "Epoch 169/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7879 - loss: 0.4972 - val_accuracy: 0.6875 - val_loss: 0.4577\n",
      "Epoch 170/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7679 - loss: 0.4589 - val_accuracy: 0.6875 - val_loss: 0.4552\n",
      "Epoch 171/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7606 - loss: 0.4776 - val_accuracy: 0.6875 - val_loss: 0.4546\n",
      "Epoch 172/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7886 - loss: 0.4443 - val_accuracy: 0.6875 - val_loss: 0.4546\n",
      "Epoch 173/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7612 - loss: 0.4518 - val_accuracy: 0.6875 - val_loss: 0.4537\n",
      "Epoch 174/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7794 - loss: 0.4606 - val_accuracy: 0.6875 - val_loss: 0.4533\n",
      "Epoch 175/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7860 - loss: 0.4536 - val_accuracy: 0.6875 - val_loss: 0.4534\n",
      "Epoch 176/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7600 - loss: 0.4954 - val_accuracy: 0.6875 - val_loss: 0.4524\n",
      "Epoch 177/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7810 - loss: 0.4674 - val_accuracy: 0.6875 - val_loss: 0.4529\n",
      "Epoch 178/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7893 - loss: 0.4525 - val_accuracy: 0.6875 - val_loss: 0.4520\n",
      "Epoch 179/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7781 - loss: 0.4577 - val_accuracy: 0.6875 - val_loss: 0.4495\n",
      "Epoch 180/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8088 - loss: 0.4206 - val_accuracy: 0.6875 - val_loss: 0.4503\n",
      "Epoch 181/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7871 - loss: 0.4503 - val_accuracy: 0.6875 - val_loss: 0.4485\n",
      "Epoch 182/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7860 - loss: 0.4512 - val_accuracy: 0.6875 - val_loss: 0.4487\n",
      "Epoch 183/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8077 - loss: 0.4342 - val_accuracy: 0.6875 - val_loss: 0.4482\n",
      "Epoch 184/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7926 - loss: 0.4308 - val_accuracy: 0.6875 - val_loss: 0.4469\n",
      "Epoch 185/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7720 - loss: 0.4347 - val_accuracy: 0.6875 - val_loss: 0.4458\n",
      "Epoch 186/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7710 - loss: 0.4449 - val_accuracy: 0.6875 - val_loss: 0.4453\n",
      "Epoch 187/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7573 - loss: 0.4641 - val_accuracy: 0.6875 - val_loss: 0.4456\n",
      "Epoch 188/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7637 - loss: 0.4569 - val_accuracy: 0.6875 - val_loss: 0.4459\n",
      "Epoch 189/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8025 - loss: 0.4399 - val_accuracy: 0.6875 - val_loss: 0.4449\n",
      "Epoch 190/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7952 - loss: 0.4533 - val_accuracy: 0.6875 - val_loss: 0.4442\n",
      "Epoch 191/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7966 - loss: 0.4362 - val_accuracy: 0.6875 - val_loss: 0.4428\n",
      "Epoch 192/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8015 - loss: 0.4399 - val_accuracy: 0.6875 - val_loss: 0.4425\n",
      "Epoch 193/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7988 - loss: 0.4577 - val_accuracy: 0.6875 - val_loss: 0.4430\n",
      "Epoch 194/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7442 - loss: 0.4616 - val_accuracy: 0.6875 - val_loss: 0.4410\n",
      "Epoch 195/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8052 - loss: 0.4522 - val_accuracy: 0.6875 - val_loss: 0.4410\n",
      "Epoch 196/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7927 - loss: 0.4619 - val_accuracy: 0.6875 - val_loss: 0.4412\n",
      "Epoch 197/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7684 - loss: 0.4736 - val_accuracy: 0.6875 - val_loss: 0.4400\n",
      "Epoch 198/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7965 - loss: 0.4320 - val_accuracy: 0.6875 - val_loss: 0.4396\n",
      "Epoch 199/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8195 - loss: 0.4272 - val_accuracy: 0.6875 - val_loss: 0.4388\n",
      "Epoch 200/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8419 - loss: 0.4095 - val_accuracy: 0.6875 - val_loss: 0.4398\n",
      "Epoch 201/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8104 - loss: 0.4176 - val_accuracy: 0.6875 - val_loss: 0.4386\n",
      "Epoch 202/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7734 - loss: 0.4572 - val_accuracy: 0.6875 - val_loss: 0.4370\n",
      "Epoch 203/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7513 - loss: 0.4886 - val_accuracy: 0.6875 - val_loss: 0.4363\n",
      "Epoch 204/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7503 - loss: 0.4607 - val_accuracy: 0.6875 - val_loss: 0.4347\n",
      "Epoch 205/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7835 - loss: 0.4367 - val_accuracy: 0.6875 - val_loss: 0.4359\n",
      "Epoch 206/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7882 - loss: 0.4490 - val_accuracy: 0.6875 - val_loss: 0.4362\n",
      "Epoch 207/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8028 - loss: 0.4420 - val_accuracy: 0.6875 - val_loss: 0.4352\n",
      "Epoch 208/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7892 - loss: 0.4480 - val_accuracy: 0.6875 - val_loss: 0.4347\n",
      "Epoch 209/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7550 - loss: 0.4649 - val_accuracy: 0.6875 - val_loss: 0.4328\n",
      "Epoch 210/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7902 - loss: 0.4257 - val_accuracy: 0.6875 - val_loss: 0.4325\n",
      "Epoch 211/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7886 - loss: 0.4172 - val_accuracy: 0.6875 - val_loss: 0.4324\n",
      "Epoch 212/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7957 - loss: 0.4251 - val_accuracy: 0.6875 - val_loss: 0.4324\n",
      "Epoch 213/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7861 - loss: 0.4623 - val_accuracy: 0.6875 - val_loss: 0.4322\n",
      "Epoch 214/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7951 - loss: 0.4460 - val_accuracy: 0.6875 - val_loss: 0.4313\n",
      "Epoch 215/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7992 - loss: 0.4268 - val_accuracy: 0.6875 - val_loss: 0.4302\n",
      "Epoch 216/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7907 - loss: 0.4337 - val_accuracy: 0.6875 - val_loss: 0.4304\n",
      "Epoch 217/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7786 - loss: 0.4518 - val_accuracy: 0.6875 - val_loss: 0.4292\n",
      "Epoch 218/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7972 - loss: 0.4394 - val_accuracy: 0.6875 - val_loss: 0.4280\n",
      "Epoch 219/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7859 - loss: 0.4361 - val_accuracy: 0.6875 - val_loss: 0.4282\n",
      "Epoch 220/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7727 - loss: 0.4334 - val_accuracy: 0.6875 - val_loss: 0.4275\n",
      "Epoch 221/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7929 - loss: 0.4398 - val_accuracy: 0.6875 - val_loss: 0.4279\n",
      "Epoch 222/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7907 - loss: 0.4368 - val_accuracy: 0.6875 - val_loss: 0.4274\n",
      "Epoch 223/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7741 - loss: 0.4477 - val_accuracy: 0.6875 - val_loss: 0.4276\n",
      "Epoch 224/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7829 - loss: 0.4294 - val_accuracy: 0.6875 - val_loss: 0.4272\n",
      "Epoch 225/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8199 - loss: 0.3940 - val_accuracy: 0.6875 - val_loss: 0.4260\n",
      "Epoch 226/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7695 - loss: 0.4310 - val_accuracy: 0.6875 - val_loss: 0.4244\n",
      "Epoch 227/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7769 - loss: 0.4414 - val_accuracy: 0.6875 - val_loss: 0.4248\n",
      "Epoch 228/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8051 - loss: 0.4022 - val_accuracy: 0.6875 - val_loss: 0.4246\n",
      "Epoch 229/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7940 - loss: 0.4506 - val_accuracy: 0.6875 - val_loss: 0.4246\n",
      "Epoch 230/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8002 - loss: 0.4394 - val_accuracy: 0.6875 - val_loss: 0.4245\n",
      "Epoch 231/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7885 - loss: 0.4458 - val_accuracy: 0.6875 - val_loss: 0.4233\n",
      "Epoch 232/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7843 - loss: 0.4104 - val_accuracy: 0.6875 - val_loss: 0.4222\n",
      "Epoch 233/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7787 - loss: 0.4200 - val_accuracy: 0.6875 - val_loss: 0.4211\n",
      "Epoch 234/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7966 - loss: 0.4418 - val_accuracy: 0.6875 - val_loss: 0.4220\n",
      "Epoch 235/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7884 - loss: 0.4479 - val_accuracy: 0.6875 - val_loss: 0.4217\n",
      "Epoch 236/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7901 - loss: 0.4165 - val_accuracy: 0.6875 - val_loss: 0.4213\n",
      "Epoch 237/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8155 - loss: 0.3810 - val_accuracy: 0.6875 - val_loss: 0.4206\n",
      "Epoch 238/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7731 - loss: 0.4419 - val_accuracy: 0.6875 - val_loss: 0.4197\n",
      "Epoch 239/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7823 - loss: 0.4352 - val_accuracy: 0.6875 - val_loss: 0.4194\n",
      "Epoch 240/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7883 - loss: 0.4301 - val_accuracy: 0.6875 - val_loss: 0.4197\n",
      "Epoch 241/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7741 - loss: 0.4287 - val_accuracy: 0.6875 - val_loss: 0.4186\n",
      "Epoch 242/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7993 - loss: 0.4081 - val_accuracy: 0.6875 - val_loss: 0.4185\n",
      "Epoch 243/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7970 - loss: 0.4347 - val_accuracy: 0.6875 - val_loss: 0.4191\n",
      "Epoch 244/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7728 - loss: 0.4329 - val_accuracy: 0.6875 - val_loss: 0.4187\n",
      "Epoch 245/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7742 - loss: 0.4413 - val_accuracy: 0.6875 - val_loss: 0.4176\n",
      "Epoch 246/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7876 - loss: 0.4191 - val_accuracy: 0.6875 - val_loss: 0.4168\n",
      "Epoch 247/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7421 - loss: 0.4607 - val_accuracy: 0.6875 - val_loss: 0.4155\n",
      "Epoch 248/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7760 - loss: 0.4431 - val_accuracy: 0.6875 - val_loss: 0.4159\n",
      "Epoch 249/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8009 - loss: 0.4269 - val_accuracy: 0.6875 - val_loss: 0.4166\n",
      "Epoch 250/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7898 - loss: 0.4087 - val_accuracy: 0.6875 - val_loss: 0.4167\n",
      "Epoch 251/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7851 - loss: 0.4153 - val_accuracy: 0.6875 - val_loss: 0.4152\n",
      "Epoch 252/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7872 - loss: 0.4230 - val_accuracy: 0.6875 - val_loss: 0.4149\n",
      "Epoch 253/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7912 - loss: 0.4127 - val_accuracy: 0.6875 - val_loss: 0.4144\n",
      "Epoch 254/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7536 - loss: 0.4581 - val_accuracy: 0.6875 - val_loss: 0.4130\n",
      "Epoch 255/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7606 - loss: 0.4570 - val_accuracy: 0.6875 - val_loss: 0.4135\n",
      "Epoch 256/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7905 - loss: 0.4144 - val_accuracy: 0.6875 - val_loss: 0.4126\n",
      "Epoch 257/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7914 - loss: 0.3987 - val_accuracy: 0.6875 - val_loss: 0.4122\n",
      "Epoch 258/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7675 - loss: 0.4462 - val_accuracy: 0.6875 - val_loss: 0.4133\n",
      "Epoch 259/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7686 - loss: 0.4443 - val_accuracy: 0.6875 - val_loss: 0.4116\n",
      "Epoch 260/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7872 - loss: 0.4642 - val_accuracy: 0.6875 - val_loss: 0.4129\n",
      "Epoch 261/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7664 - loss: 0.4351 - val_accuracy: 0.6875 - val_loss: 0.4116\n",
      "Epoch 262/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7907 - loss: 0.4246 - val_accuracy: 0.6875 - val_loss: 0.4117\n",
      "Epoch 263/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7895 - loss: 0.4152 - val_accuracy: 0.6875 - val_loss: 0.4116\n",
      "Epoch 264/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8163 - loss: 0.3925 - val_accuracy: 0.6875 - val_loss: 0.4105\n",
      "Epoch 265/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8042 - loss: 0.4005 - val_accuracy: 0.6875 - val_loss: 0.4101\n",
      "Epoch 266/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7882 - loss: 0.4104 - val_accuracy: 0.6875 - val_loss: 0.4092\n",
      "Epoch 267/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8117 - loss: 0.4000 - val_accuracy: 0.6875 - val_loss: 0.4088\n",
      "Epoch 268/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7888 - loss: 0.4201 - val_accuracy: 0.6875 - val_loss: 0.4093\n",
      "Epoch 269/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7294 - loss: 0.4544 - val_accuracy: 0.6875 - val_loss: 0.4069\n",
      "Epoch 270/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7835 - loss: 0.4624 - val_accuracy: 0.6875 - val_loss: 0.4074\n",
      "Epoch 271/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7696 - loss: 0.4418 - val_accuracy: 0.6875 - val_loss: 0.4076\n",
      "Epoch 272/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8210 - loss: 0.3924 - val_accuracy: 0.6875 - val_loss: 0.4085\n",
      "Epoch 273/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7691 - loss: 0.4173 - val_accuracy: 0.6875 - val_loss: 0.4066\n",
      "Epoch 274/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7835 - loss: 0.3995 - val_accuracy: 0.6875 - val_loss: 0.4060\n",
      "Epoch 275/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7959 - loss: 0.4220 - val_accuracy: 0.6875 - val_loss: 0.4056\n",
      "Epoch 276/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7893 - loss: 0.4084 - val_accuracy: 0.6875 - val_loss: 0.4061\n",
      "Epoch 277/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7909 - loss: 0.3937 - val_accuracy: 0.6875 - val_loss: 0.4054\n",
      "Epoch 278/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7847 - loss: 0.4116 - val_accuracy: 0.6875 - val_loss: 0.4044\n",
      "Epoch 279/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7944 - loss: 0.4401 - val_accuracy: 0.6875 - val_loss: 0.4057\n",
      "Epoch 280/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7773 - loss: 0.4418 - val_accuracy: 0.6875 - val_loss: 0.4046\n",
      "Epoch 281/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7855 - loss: 0.4275 - val_accuracy: 0.6875 - val_loss: 0.4048\n",
      "Epoch 282/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7856 - loss: 0.4353 - val_accuracy: 0.6875 - val_loss: 0.4048\n",
      "Epoch 283/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7738 - loss: 0.3981 - val_accuracy: 0.6875 - val_loss: 0.4031\n",
      "Epoch 284/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7860 - loss: 0.4049 - val_accuracy: 0.6875 - val_loss: 0.4034\n",
      "Epoch 285/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7796 - loss: 0.4120 - val_accuracy: 0.6875 - val_loss: 0.4035\n",
      "Epoch 286/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7578 - loss: 0.4106 - val_accuracy: 0.6875 - val_loss: 0.4030\n",
      "Epoch 287/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7790 - loss: 0.4316 - val_accuracy: 0.6875 - val_loss: 0.4034\n",
      "Epoch 288/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7959 - loss: 0.4041 - val_accuracy: 0.6875 - val_loss: 0.4027\n",
      "Epoch 289/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7940 - loss: 0.3966 - val_accuracy: 0.6875 - val_loss: 0.4016\n",
      "Epoch 290/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7616 - loss: 0.4422 - val_accuracy: 0.6875 - val_loss: 0.4006\n",
      "Epoch 291/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7760 - loss: 0.4337 - val_accuracy: 0.6875 - val_loss: 0.4011\n",
      "Epoch 292/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7829 - loss: 0.4125 - val_accuracy: 0.6875 - val_loss: 0.4006\n",
      "Epoch 293/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7829 - loss: 0.3980 - val_accuracy: 0.6875 - val_loss: 0.4005\n",
      "Epoch 294/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8077 - loss: 0.4162 - val_accuracy: 0.6875 - val_loss: 0.4010\n",
      "Epoch 295/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7724 - loss: 0.4022 - val_accuracy: 0.6875 - val_loss: 0.3994\n",
      "Epoch 296/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8083 - loss: 0.4004 - val_accuracy: 0.6875 - val_loss: 0.4001\n",
      "Epoch 297/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7968 - loss: 0.3939 - val_accuracy: 0.6875 - val_loss: 0.3993\n",
      "Epoch 298/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7851 - loss: 0.3970 - val_accuracy: 0.6875 - val_loss: 0.3996\n",
      "Epoch 299/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7983 - loss: 0.4004 - val_accuracy: 0.6875 - val_loss: 0.3991\n",
      "Epoch 300/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8183 - loss: 0.3650 - val_accuracy: 0.6875 - val_loss: 0.3983\n",
      "Epoch 301/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7730 - loss: 0.4011 - val_accuracy: 0.6875 - val_loss: 0.3972\n",
      "Epoch 302/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7863 - loss: 0.4219 - val_accuracy: 0.6875 - val_loss: 0.3977\n",
      "Epoch 303/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7987 - loss: 0.3946 - val_accuracy: 0.6875 - val_loss: 0.3977\n",
      "Epoch 304/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7655 - loss: 0.4447 - val_accuracy: 0.6875 - val_loss: 0.3972\n",
      "Epoch 305/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8015 - loss: 0.4350 - val_accuracy: 0.6875 - val_loss: 0.3987\n",
      "Epoch 306/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7771 - loss: 0.4322 - val_accuracy: 0.6875 - val_loss: 0.3973\n",
      "Epoch 307/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7870 - loss: 0.3871 - val_accuracy: 0.6875 - val_loss: 0.3964\n",
      "Epoch 308/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7798 - loss: 0.3903 - val_accuracy: 0.6875 - val_loss: 0.3946\n",
      "Epoch 309/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8047 - loss: 0.3954 - val_accuracy: 0.6875 - val_loss: 0.3960\n",
      "Epoch 310/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8093 - loss: 0.4006 - val_accuracy: 0.6875 - val_loss: 0.3960\n",
      "Epoch 311/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7999 - loss: 0.4273 - val_accuracy: 0.6875 - val_loss: 0.3959\n",
      "Epoch 312/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8004 - loss: 0.3876 - val_accuracy: 0.6875 - val_loss: 0.3952\n",
      "Epoch 313/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7911 - loss: 0.4251 - val_accuracy: 0.6875 - val_loss: 0.3956\n",
      "Epoch 314/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7500 - loss: 0.4548 - val_accuracy: 0.6875 - val_loss: 0.3947\n",
      "Epoch 315/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7713 - loss: 0.4097 - val_accuracy: 0.6875 - val_loss: 0.3940\n",
      "Epoch 316/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7806 - loss: 0.4311 - val_accuracy: 0.6875 - val_loss: 0.3944\n",
      "Epoch 317/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7936 - loss: 0.3978 - val_accuracy: 0.6875 - val_loss: 0.3938\n",
      "Epoch 318/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7703 - loss: 0.4184 - val_accuracy: 0.6875 - val_loss: 0.3917\n",
      "Epoch 319/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7971 - loss: 0.3922 - val_accuracy: 0.6875 - val_loss: 0.3926\n",
      "Epoch 320/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7734 - loss: 0.4298 - val_accuracy: 0.6875 - val_loss: 0.3929\n",
      "Epoch 321/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7770 - loss: 0.4190 - val_accuracy: 0.6875 - val_loss: 0.3919\n",
      "Epoch 322/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7890 - loss: 0.4099 - val_accuracy: 0.6875 - val_loss: 0.3923\n",
      "Epoch 323/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7921 - loss: 0.3987 - val_accuracy: 0.6875 - val_loss: 0.3930\n",
      "Epoch 324/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7914 - loss: 0.4346 - val_accuracy: 0.6875 - val_loss: 0.3928\n",
      "Epoch 325/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8188 - loss: 0.3957 - val_accuracy: 0.6875 - val_loss: 0.3932\n",
      "Epoch 326/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7796 - loss: 0.3717 - val_accuracy: 0.6875 - val_loss: 0.3916\n",
      "Epoch 327/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7751 - loss: 0.3952 - val_accuracy: 0.6875 - val_loss: 0.3905\n",
      "Epoch 328/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8070 - loss: 0.3637 - val_accuracy: 0.6875 - val_loss: 0.3907\n",
      "Epoch 329/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7713 - loss: 0.4007 - val_accuracy: 0.6875 - val_loss: 0.3911\n",
      "Epoch 330/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7872 - loss: 0.3856 - val_accuracy: 0.6875 - val_loss: 0.3905\n",
      "Epoch 331/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.3778 - val_accuracy: 0.6875 - val_loss: 0.3894\n",
      "Epoch 332/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7960 - loss: 0.3817 - val_accuracy: 0.6875 - val_loss: 0.3887\n",
      "Epoch 333/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7548 - loss: 0.4156 - val_accuracy: 0.6875 - val_loss: 0.3890\n",
      "Epoch 334/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7711 - loss: 0.4130 - val_accuracy: 0.6875 - val_loss: 0.3886\n",
      "Epoch 335/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7867 - loss: 0.3963 - val_accuracy: 0.6875 - val_loss: 0.3891\n",
      "Epoch 336/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8099 - loss: 0.3780 - val_accuracy: 0.6875 - val_loss: 0.3901\n",
      "Epoch 337/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7903 - loss: 0.4000 - val_accuracy: 0.6875 - val_loss: 0.3884\n",
      "Epoch 338/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7967 - loss: 0.3737 - val_accuracy: 0.6875 - val_loss: 0.3887\n",
      "Epoch 339/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8176 - loss: 0.3792 - val_accuracy: 0.6875 - val_loss: 0.3883\n",
      "Epoch 340/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8084 - loss: 0.3944 - val_accuracy: 0.6875 - val_loss: 0.3875\n",
      "Epoch 341/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8207 - loss: 0.3630 - val_accuracy: 0.6875 - val_loss: 0.3876\n",
      "Epoch 342/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7570 - loss: 0.4244 - val_accuracy: 0.6875 - val_loss: 0.3873\n",
      "Epoch 343/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7783 - loss: 0.3831 - val_accuracy: 0.6875 - val_loss: 0.3871\n",
      "Epoch 344/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7936 - loss: 0.3831 - val_accuracy: 0.6875 - val_loss: 0.3861\n",
      "Epoch 345/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8122 - loss: 0.3782 - val_accuracy: 0.6875 - val_loss: 0.3878\n",
      "Epoch 346/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7930 - loss: 0.4037 - val_accuracy: 0.6875 - val_loss: 0.3871\n",
      "Epoch 347/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7843 - loss: 0.4034 - val_accuracy: 0.6875 - val_loss: 0.3864\n",
      "Epoch 348/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7797 - loss: 0.3986 - val_accuracy: 0.6875 - val_loss: 0.3854\n",
      "Epoch 349/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7827 - loss: 0.3895 - val_accuracy: 0.6875 - val_loss: 0.3854\n",
      "Epoch 350/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7959 - loss: 0.3664 - val_accuracy: 0.6875 - val_loss: 0.3857\n",
      "Epoch 351/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8076 - loss: 0.3814 - val_accuracy: 0.6875 - val_loss: 0.3856\n",
      "Epoch 352/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7827 - loss: 0.3751 - val_accuracy: 0.6875 - val_loss: 0.3846\n",
      "Epoch 353/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7989 - loss: 0.3760 - val_accuracy: 0.6875 - val_loss: 0.3840\n",
      "Epoch 354/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7738 - loss: 0.3984 - val_accuracy: 0.6875 - val_loss: 0.3842\n",
      "Epoch 355/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7786 - loss: 0.3965 - val_accuracy: 0.6875 - val_loss: 0.3844\n",
      "Epoch 356/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7934 - loss: 0.4157 - val_accuracy: 0.6875 - val_loss: 0.3850\n",
      "Epoch 357/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7876 - loss: 0.3855 - val_accuracy: 0.6875 - val_loss: 0.3843\n",
      "Epoch 358/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7991 - loss: 0.3867 - val_accuracy: 0.6875 - val_loss: 0.3841\n",
      "Epoch 359/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7932 - loss: 0.3824 - val_accuracy: 0.6875 - val_loss: 0.3841\n",
      "Epoch 360/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7978 - loss: 0.3812 - val_accuracy: 0.6875 - val_loss: 0.3835\n",
      "Epoch 361/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7434 - loss: 0.4356 - val_accuracy: 0.6875 - val_loss: 0.3832\n",
      "Epoch 362/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7954 - loss: 0.3938 - val_accuracy: 0.6875 - val_loss: 0.3830\n",
      "Epoch 363/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7807 - loss: 0.4155 - val_accuracy: 0.6875 - val_loss: 0.3831\n",
      "Epoch 364/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7777 - loss: 0.3805 - val_accuracy: 0.6875 - val_loss: 0.3824\n",
      "Epoch 365/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7684 - loss: 0.3894 - val_accuracy: 0.6875 - val_loss: 0.3814\n",
      "Epoch 366/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7847 - loss: 0.4007 - val_accuracy: 0.6875 - val_loss: 0.3819\n",
      "Epoch 367/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7895 - loss: 0.3787 - val_accuracy: 0.6875 - val_loss: 0.3808\n",
      "Epoch 368/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7788 - loss: 0.4180 - val_accuracy: 0.6875 - val_loss: 0.3807\n",
      "Epoch 369/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8004 - loss: 0.3521 - val_accuracy: 0.6875 - val_loss: 0.3812\n",
      "Epoch 370/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7691 - loss: 0.3769 - val_accuracy: 0.6875 - val_loss: 0.3813\n",
      "Epoch 371/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7721 - loss: 0.3819 - val_accuracy: 0.6875 - val_loss: 0.3812\n",
      "Epoch 372/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7769 - loss: 0.3949 - val_accuracy: 0.6875 - val_loss: 0.3808\n",
      "Epoch 373/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7566 - loss: 0.4132 - val_accuracy: 0.6875 - val_loss: 0.3814\n",
      "Epoch 374/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7937 - loss: 0.4109 - val_accuracy: 0.6875 - val_loss: 0.3811\n",
      "Epoch 375/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8202 - loss: 0.3468 - val_accuracy: 0.6875 - val_loss: 0.3805\n",
      "Epoch 376/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8013 - loss: 0.3872 - val_accuracy: 0.6875 - val_loss: 0.3810\n",
      "Epoch 377/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8005 - loss: 0.3724 - val_accuracy: 0.6875 - val_loss: 0.3812\n",
      "Epoch 378/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8156 - loss: 0.3830 - val_accuracy: 0.6875 - val_loss: 0.3800\n",
      "Epoch 379/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7876 - loss: 0.4169 - val_accuracy: 0.6875 - val_loss: 0.3808\n",
      "Epoch 380/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8208 - loss: 0.3524 - val_accuracy: 0.6875 - val_loss: 0.3794\n",
      "Epoch 381/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7893 - loss: 0.3987 - val_accuracy: 0.6875 - val_loss: 0.3784\n",
      "Epoch 382/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7732 - loss: 0.4179 - val_accuracy: 0.6875 - val_loss: 0.3782\n",
      "Epoch 383/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7924 - loss: 0.3965 - val_accuracy: 0.6875 - val_loss: 0.3785\n",
      "Epoch 384/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7892 - loss: 0.3817 - val_accuracy: 0.6875 - val_loss: 0.3779\n",
      "Epoch 385/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7868 - loss: 0.4069 - val_accuracy: 0.6875 - val_loss: 0.3783\n",
      "Epoch 386/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7748 - loss: 0.3995 - val_accuracy: 0.6875 - val_loss: 0.3786\n",
      "Epoch 387/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7768 - loss: 0.4036 - val_accuracy: 0.6875 - val_loss: 0.3782\n",
      "Epoch 388/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8031 - loss: 0.3650 - val_accuracy: 0.6875 - val_loss: 0.3775\n",
      "Epoch 389/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7747 - loss: 0.3844 - val_accuracy: 0.6875 - val_loss: 0.3778\n",
      "Epoch 390/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7853 - loss: 0.4052 - val_accuracy: 0.6875 - val_loss: 0.3773\n",
      "Epoch 391/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7853 - loss: 0.3853 - val_accuracy: 0.6875 - val_loss: 0.3771\n",
      "Epoch 392/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8095 - loss: 0.3712 - val_accuracy: 0.6875 - val_loss: 0.3762\n",
      "Epoch 393/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7856 - loss: 0.4225 - val_accuracy: 0.6875 - val_loss: 0.3773\n",
      "Epoch 394/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7790 - loss: 0.4180 - val_accuracy: 0.6875 - val_loss: 0.3770\n",
      "Epoch 395/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8255 - loss: 0.3706 - val_accuracy: 0.6875 - val_loss: 0.3777\n",
      "Epoch 396/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7767 - loss: 0.3876 - val_accuracy: 0.6875 - val_loss: 0.3753\n",
      "Epoch 397/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8109 - loss: 0.3755 - val_accuracy: 0.6875 - val_loss: 0.3759\n",
      "Epoch 398/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8076 - loss: 0.3817 - val_accuracy: 0.6875 - val_loss: 0.3763\n",
      "Epoch 399/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7727 - loss: 0.4106 - val_accuracy: 0.6875 - val_loss: 0.3752\n",
      "Epoch 400/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7874 - loss: 0.4186 - val_accuracy: 0.6875 - val_loss: 0.3751\n",
      "Epoch 401/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8034 - loss: 0.3615 - val_accuracy: 0.6875 - val_loss: 0.3755\n",
      "Epoch 402/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7788 - loss: 0.3933 - val_accuracy: 0.6875 - val_loss: 0.3750\n",
      "Epoch 403/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7952 - loss: 0.3905 - val_accuracy: 0.6875 - val_loss: 0.3756\n",
      "Epoch 404/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7947 - loss: 0.3954 - val_accuracy: 0.6875 - val_loss: 0.3754\n",
      "Epoch 405/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7855 - loss: 0.3830 - val_accuracy: 0.6875 - val_loss: 0.3737\n",
      "Epoch 406/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7785 - loss: 0.4057 - val_accuracy: 0.6875 - val_loss: 0.3731\n",
      "Epoch 407/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7916 - loss: 0.3700 - val_accuracy: 0.6875 - val_loss: 0.3743\n",
      "Epoch 408/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7965 - loss: 0.3741 - val_accuracy: 0.6875 - val_loss: 0.3756\n",
      "Epoch 409/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8065 - loss: 0.3815 - val_accuracy: 0.6875 - val_loss: 0.3743\n",
      "Epoch 410/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7805 - loss: 0.3844 - val_accuracy: 0.6875 - val_loss: 0.3734\n",
      "Epoch 411/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7681 - loss: 0.4151 - val_accuracy: 0.6875 - val_loss: 0.3733\n",
      "Epoch 412/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7773 - loss: 0.3841 - val_accuracy: 0.6875 - val_loss: 0.3735\n",
      "Epoch 413/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7929 - loss: 0.3836 - val_accuracy: 0.6875 - val_loss: 0.3737\n",
      "Epoch 414/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8122 - loss: 0.3766 - val_accuracy: 0.6875 - val_loss: 0.3746\n",
      "Epoch 415/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7871 - loss: 0.4002 - val_accuracy: 0.6875 - val_loss: 0.3734\n",
      "Epoch 416/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7977 - loss: 0.3957 - val_accuracy: 0.6875 - val_loss: 0.3725\n",
      "Epoch 417/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8269 - loss: 0.3576 - val_accuracy: 0.6875 - val_loss: 0.3724\n",
      "Epoch 418/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8200 - loss: 0.3566 - val_accuracy: 0.6875 - val_loss: 0.3724\n",
      "Epoch 419/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8015 - loss: 0.3748 - val_accuracy: 0.6875 - val_loss: 0.3723\n",
      "Epoch 420/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7623 - loss: 0.4282 - val_accuracy: 0.6875 - val_loss: 0.3711\n",
      "Epoch 421/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7852 - loss: 0.4020 - val_accuracy: 0.6875 - val_loss: 0.3719\n",
      "Epoch 422/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8168 - loss: 0.3680 - val_accuracy: 0.6875 - val_loss: 0.3726\n",
      "Epoch 423/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8024 - loss: 0.3910 - val_accuracy: 0.6875 - val_loss: 0.3727\n",
      "Epoch 424/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7659 - loss: 0.4068 - val_accuracy: 0.6875 - val_loss: 0.3716\n",
      "Epoch 425/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8002 - loss: 0.3649 - val_accuracy: 0.6875 - val_loss: 0.3717\n",
      "Epoch 426/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7913 - loss: 0.3837 - val_accuracy: 0.6875 - val_loss: 0.3716\n",
      "Epoch 427/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7850 - loss: 0.3846 - val_accuracy: 0.6875 - val_loss: 0.3691\n",
      "Epoch 428/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7805 - loss: 0.4065 - val_accuracy: 0.6875 - val_loss: 0.3711\n",
      "Epoch 429/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7859 - loss: 0.3922 - val_accuracy: 0.6875 - val_loss: 0.3698\n",
      "Epoch 430/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7998 - loss: 0.4019 - val_accuracy: 0.6875 - val_loss: 0.3712\n",
      "Epoch 431/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7746 - loss: 0.3907 - val_accuracy: 0.6875 - val_loss: 0.3700\n",
      "Epoch 432/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7485 - loss: 0.4127 - val_accuracy: 0.6875 - val_loss: 0.3695\n",
      "Epoch 433/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.3419 - val_accuracy: 0.6875 - val_loss: 0.3701\n",
      "Epoch 434/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7932 - loss: 0.3713 - val_accuracy: 0.6875 - val_loss: 0.3709\n",
      "Epoch 435/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8022 - loss: 0.3569 - val_accuracy: 0.6875 - val_loss: 0.3697\n",
      "Epoch 436/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7811 - loss: 0.4039 - val_accuracy: 0.6875 - val_loss: 0.3694\n",
      "Epoch 437/1000\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8201 - loss: 0.3646 - val_accuracy: 0.6875 - val_loss: 0.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25677a03cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm architecture\n",
    "model = Sequential()\n",
    "input_shape = pp.get_shape()\n",
    "# First LSTM layer\n",
    "if lstm_layers > 1:\n",
    "    model.add(LSTM(lstm_units_per_layer, input_shape=input_shape, return_sequences=True))\n",
    "else:\n",
    "    model.add(LSTM(lstm_units_per_layer, input_shape=input_shape))  # single layer, no sequences returned\n",
    "# Intermediate LSTM layers (if any)\n",
    "for i in range(lstm_layers - 2):\n",
    "    model.add(LSTM(lstm_units_per_layer, return_sequences=True))\n",
    "# Last LSTM layer (no return_sequences, output fed into Dense)\n",
    "if lstm_layers > 1:\n",
    "    model.add(LSTM(lstm_units_per_layer))\n",
    "# Dense Layer\n",
    "num_classes = len(set(y_train))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# train the model\n",
    "early_stopping = EarlyStopping(monitor=early_stopping_monitor, \n",
    "                               patience=early_stopping_patience, \n",
    "                               restore_best_weights=early_stopping_restore_best)\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1fd8d",
   "metadata": {},
   "source": [
    "Optionally save the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce5aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "filename = f\"lstm_{lstm_layers}x{lstm_units_per_layer}_drop{dropout}_rec{recurrent_dropout}_enc{message_encoder.__class__.__name__.lower()}_{logs_per_class}logs_win{window_size}_lr{learning_rate}_bs{batch_size}_ep{epochs}_{early_stopping_monitor}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "model.save(f\"{filename}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52041822",
   "metadata": {},
   "source": [
    "Evaluate model and print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f7ba17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m14,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m204\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,214</span> (168.81 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,214\u001b[0m (168.81 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,404</span> (56.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,404\u001b[0m (56.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,810</span> (112.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m28,810\u001b[0m (112.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4246\n",
      "compile_metrics: 0.7625\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.54      0.65      0.59        20\n",
      "           2       0.53      0.40      0.46        20\n",
      "           3       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.76        80\n",
      "   macro avg       0.76      0.76      0.76        80\n",
      "weighted avg       0.76      0.76      0.76        80\n",
      "\n",
      "F1 Score (weighted): 0.7559\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Classification report and F1 score\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(f\"{filename}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508e8a1",
   "metadata": {},
   "source": [
    "Save the confusion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
