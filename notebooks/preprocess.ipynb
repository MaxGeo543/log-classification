{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9a9687",
   "metadata": {},
   "source": [
    "# Parsing and Extracting Log Keys\n",
    "This section will make use of src/parse.py to parse log files and extract the log keys from them. First we import the parse file. Make sure to have it installed, to install it execute `pip install -e .` in the root directory of the project. \n",
    "\n",
    "Then we import it. To do that we first import `sys` and `os` and add the src directory to path: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f6e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from preprocessor import Preprocessor\n",
    "from message_encoder import *\n",
    "from util import get_sorted_log_numbers_by_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa906dc8",
   "metadata": {},
   "source": [
    "# Preprocessing Parameters\n",
    "Here we can set several parameters for preprocessing. The effects will be explained here: \n",
    "- `log_files` - What log files to load for pre-processing. It will load all these Logfiles for message encoding, not all of the data will be used as data\n",
    "- `logs_per_class` - How many logs should be attempted to be labeled per class. The resulting Dataset will be of size `num_classes*logs_per_class` if the end of the log files wasn't reached before that\n",
    "- `window_size` - The size of the sliding window to use for the data set. `window_size` logs will be treated as one data entry\n",
    "- `encoding_output_size` - size to be passed to the message_encoder, note that this is not neccessairily the shape of the output (for `BERTEncodingEmbedding` the shape of the output is multiplied by the length of its hidden state, typically 768)\n",
    "- `message_encoder` - The type of message encoding to use, can be one of `TextVectorizationEncoder` (uses keras.layers.TextVectorizer), `BERTEncoder` (only uses the BERT tokenizer) or `BERTEmbeddingEncoder` (also uses the BERT model)\n",
    "- `extended_datetime_features` - Whether to use simple datetime features (days since epoch and seconds since midnight) or extended datetime features which includes a multitude of normalized features extracted from the datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47163d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing parameters\n",
    "log_files = get_sorted_log_numbers_by_size(r\"C:\\Users\\Askion\\Documents\\agmge\\log-classification\\data\\CCI\")[:20]\n",
    "logs_per_class = 100\n",
    "window_size = 20\n",
    "encoding_output_size = 4\n",
    "# message_encoder = BERTEncoder(max_length=encoding_output_size)\n",
    "message_encoder = TextVectorizationEncoder(output_sequence_length=encoding_output_size)\n",
    "extended_datetime_features = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97a7da",
   "metadata": {},
   "source": [
    "The next codeblock will create a Preprocessor instance and preprocess the data. Upon instanciating the Preprocessor, all Logs will be loaded from the specified log_files, the message_encoder will be initialized with the found log messages and the function_encoder will be initialized. Since all logs will be loaded, this process takes a while. Using a Keyboard interrupt the loading of new logs can be interrupted and the Preprocessor will work with the data loaded until that point. \n",
    "\n",
    "Then the preprocessing starts which lets a sliding window slide over the logs. Each window will be labeled. If the class of the label is already full (count reached `logs_per_class`) the window will be skipped and discarded, otherwise the window and its label will be added to the dataset. Once all classes are full or there is no more data the preprocessing will stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f8fcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbf28263d4e4e3ab96888d6fe3a7fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log file CCLog-backup.749.log:   0%|          | 0/86349 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f83fb07127f44c582f70e63b1d05f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annotating events:   0%|          | 0/76720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State counts:\n",
      "  - 0 : 100\n",
      "  - 3 : 100\n",
      "  - 2 : 35\n",
      "  - 1 : 18\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "pp = Preprocessor(log_files, message_encoder, logs_per_class, window_size, extended_datetime_features, True)\n",
    "pp.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642b9d1",
   "metadata": {},
   "source": [
    "In the last step the preprocessor can be saved. Preprocessors are saved as a zip file containing all serialized data about the preprocessor as well as the complete data including preprocessed and unpreprocessed. The zip file will therefore will be relatively large. The naming scheme for the preprocessor zip files is `preprocessor_{len(loaded_files)}files_{logs_per_class}lpc_{window_size}ws_{message_encoder}x{encoding_output_size}{_extdt if extended_datetime_features}`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708f1ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Askion/Documents/agmge/log-classification/data/preprocessors/preprocessor_1files_100lpc_20ws_TextVecx4.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
